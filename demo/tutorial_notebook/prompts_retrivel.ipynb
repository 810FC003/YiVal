{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure your python version >= 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Yival with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']= 'XXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplifying Prompt Generation for LLMs with Retrieval Methods\n",
    "\n",
    "Working with Large Language Models (LLMs) like ChatGPT often involves feeding\n",
    "them prompts: short texts that give the model direction on how to respond.\n",
    "Manually crafting these prompts can be tedious. Wouldn't it be convenient if we\n",
    "could automate this process, ensuring each prompt is contextually relevant?\n",
    "Let's explore a method that does just that, using the Yival framework and the\n",
    "FAISS vector database.\n",
    "\n",
    "## **Why Automate Prompt Generation?**\n",
    "\n",
    "Think of prompts as questions or instructions you give to ChatGPT. The more\n",
    "precise the instruction, the better the model's answer. But crafting a new\n",
    "instruction for every unique scenario is time-consuming. If we could automate\n",
    "this, not only would it save time, but it'd also ensure the AI's responses are\n",
    "consistently relevant.\n",
    "\n",
    "## **Storing Prompts: FAISS to the Rescue**\n",
    "\n",
    "We source a wide variety of prompts from [awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts).\n",
    "To quickly find the best prompt for any situation:\n",
    "\n",
    "- **We use FAISS**: This tool helps store prompts in a way that makes them quick\n",
    "  to search and retrieve.\n",
    "- **We turn prompts into 'vectors'**: By transforming prompts into a mathematical\n",
    "  format (vectors), we can easily find the most fitting one for a given situation.\n",
    "\n",
    "## **How Yival Helps in Retrieval**\n",
    "\n",
    "Yival is like a toolbox that simplifies AI-related experimentation.\n",
    "When integrated with FAISS, it streamlines the process of fetching the right prompt.\n",
    "\n",
    "### **The Main Steps**\n",
    "\n",
    "1. **Find Matching Prompts**: Based on a given situation, Yival searches the FAISS\n",
    "    database to find similar prompts.\n",
    "2. **Refine with GPT**: Sometimes, the initially found prompts might not be perfect.\n",
    "    So, we use GPT to rerank them, ensuring we pick the most suitable one.\n",
    "\n",
    "## **Putting It All Together**\n",
    "\n",
    "With our setup, generating a prompt becomes straightforward. For ChatGPT,\n",
    "here's a simple example of how we might use a generated prompt:\n",
    "\n",
    "```python\n",
    "# Create a chat message sequence\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": str(StringWrapper(\"\", name=\"prompt\")) + f'\\n{input}'\n",
    "}]\n",
    "# Get a response from ChatGPT\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=messages\n",
    ")\n",
    "```\n",
    "\n",
    "Notice that we didn't need to provide a predefined prompt. The system took care\n",
    "of it!\n",
    "\n",
    "## **A Peek at the Process**\n",
    "\n",
    "### **Visual Flow**\n",
    "\n",
    "<img src=\"https://uninaruto.oss-cn-shanghai.aliyuncs.com/img/20230904154944.png\" width=\"80%\" >\n",
    "\n",
    "This flowchart will give you a bird's-eye view of how everything connects, from the moment we receive a use-case to generating the perfect prompt.\n",
    "\n",
    "### **Results in Real-Time**\n",
    "\n",
    "![Output Screenshot](https://github.com/YiVal/YiVal/assets/1544154/35216786-ac3c-4884-8818-68647511228d)\n",
    "\n",
    "Here's an example of what the system's output looks like in action. This gives\n",
    "you an idea of the kind of prompts it can generate and how ChatGPT might respond.\n",
    "\n",
    "## **In Conclusion**\n",
    "\n",
    "The world of AI is vast and sometimes complex. But tools like Yival and FAISS,\n",
    "when combined with LLMs like ChatGPT, can make tasks like prompt generation much\n",
    "simpler. By automating this process, we're taking a step towards more efficient\n",
    "and context-aware AI interactions.\n",
    "\n",
    "You can review the full code [here](https://github.com/YiVal/YiVal/tree/master/demo/prompts_retrivel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YIVALÔºÅ\n",
    "\n",
    "Test from the interactive mode page on the web, input the parameters you want (such as San Francisco in our example) and select combinations. Click run, then wait to check the corresponding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n",
    "!yival run demo/configs/config_prompts_retrivel.yml"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
