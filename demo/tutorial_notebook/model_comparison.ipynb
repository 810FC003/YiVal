{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison with YIVALüßö‚Äç‚ôÄÔ∏è\n",
    "\n",
    "Try experiment mode\n",
    "\n",
    "Evaluate different models in really an easy way and find result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yival supports 100+ llm model now\n",
    "\n",
    "| Model        | llm-Evaluate |Human-Evaluate|Variation Generate|Custom func|\n",
    "|--------------| ---- | ---- | ---- |--------------|\n",
    "| OpenAI  | ‚úÖ  | ‚úÖ  | ‚úÖ  |‚úÖ|\n",
    "| Azure   | ‚úÖ  | ‚úÖ  | ‚úÖ  |‚úÖ|\n",
    "| TogetherAI | ‚úÖ | ‚úÖ | ‚úÖ  |‚úÖ|\n",
    "| Cohere | ‚úÖ | ‚úÖ | ‚úÖ |‚úÖ|\n",
    "| Huggingface | ‚úÖ | ‚úÖ | ‚úÖ |‚úÖ|\n",
    "| Anthropic | ‚úÖ | ‚úÖ | ‚úÖ |‚úÖ|\n",
    "| MidJourney | | ‚úÖ |  |‚úÖ|\n",
    "\n",
    "To support different models in custom func(e.g. Model Comparison) , [follow our example](https://github.com/YiVal/YiVal/blob/litellm_complete/demo/configs/model_compare.yml)\n",
    "\n",
    "To support different models in evaluators and generators , [check our config](https://github.com/YiVal/YiVal/blob/litellm_complete/demo/configs/headline_generation.yml)\n",
    "\n",
    "In this demo , we will compare four llm-model in QA ability\n",
    "* gpt-3.5-turbo\n",
    "* llama-2-13b-chat\n",
    "* llama-2-70b-chat\n",
    "* vicuna-13b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure your openai api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure your [replicate key](https://replicate.com/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.envirion['REPLICATE_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compare demo\n",
    "```\n",
    "custom_function: demo.model_compare.model_compare\n",
    "dataset:\n",
    "  file_path: demo/data/model_compare.csv\n",
    "  reader: csv_reader\n",
    "  source_type: dataset\n",
    "  reader_config:\n",
    "    expected_result_column: expected_result\n",
    "description: Configuration fo question answering with expected results.\n",
    "evaluators:\n",
    "  - evaluator_type: individual\n",
    "    matching_technique: includes\n",
    "    metric_calculators:\n",
    "      - method: AVERAGE\n",
    "    name: string_expected_result\n",
    "\n",
    "variations:\n",
    "  - name: model_name\n",
    "    variations:\n",
    "      - instantiated_value: \"gpt-3.5-turbo\"\n",
    "        value: \"gpt-3.5-turbo\"\n",
    "        value_type: str\n",
    "        variation_id: null\n",
    "      - instantiated_value: \"a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\"\n",
    "        value: \"a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\"\n",
    "        value_type: str\n",
    "        variation_id: null\n",
    "      - instantiated_value: \"replicate/llama-2-70b-chat:2796ee9483c3fd7aa2e171d38f4ca12251a30609463dcfd4cd76703f22e96cdf\"\n",
    "        value: \"replicate/llama-2-70b-chat:2796ee9483c3fd7aa2e171d38f4ca12251a30609463dcfd4cd76703f22e96cdf\"\n",
    "        value_type: str\n",
    "        variation_id: null\n",
    "      - instantiated_value: \"replicate/vicuna-13b:6282abe6a492de4145d7bb601023762212f9ddbbe78278bd6771c8b3b2f2a13b\"\n",
    "        value: \"replicate/vicuna-13b:6282abe6a492de4145d7bb601023762212f9ddbbe78278bd6771c8b3b2f2a13b\"\n",
    "        value_type: str\n",
    "        variation_id: null\n",
    "```\n",
    "\n",
    "In this demo , we try to compare gpt-3.5-turbo , llama2-13b-chat , llama-2-70b-chat , vicuna-13b with their ability in QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run yival run /content/YiVal/demo/configs/model_compare.yml"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
